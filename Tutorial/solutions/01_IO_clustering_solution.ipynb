{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 IO, Dimensional Reduction, and Clustering\n",
    "\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" title='This work is licensed under a Creative Commons Attribution 4.0 International License.' align=\"right\"/></a>\n",
    "\n",
    "Author: [Antonia Mey -- @ppxasjsm](https://github.com/ppxasjsm)\n",
    "\n",
    "## Learning objectives:\n",
    "- Load a molecular trajectory\n",
    "- Extract different features from the trajectory, such as backbone torsions or heavy atom positions\n",
    "- Cluster trajectory data using k-means or regular spatial clustering\n",
    "- Understand what the differences between TICA, PCA and VAMP are for dimensionality reduction methods and how to cluster on reduced spaces. \n",
    "\n",
    "You will be using the following functions in pyemma:\n",
    "\n",
    "- `pyemma.coordinates.featurizer()` to define a selection of features we want to extract,\n",
    "- `pyemma.coordinates.load()` to load data into memory, and\n",
    "- `pyemma.coordinates.source()` to create a streamed feature reader in case the data does not fit into memory.\n",
    "- `pyemma.plots.plot_feature_histograms()` to show the distributions of all loaded features,\n",
    "- `pyemma.plots.plot_density()` to visualize the sample density, and\n",
    "- `pyemma.plots.plot_free_energy()` to visualize the free energy surface of two selected features.\n",
    "- `pyemma.coordinates.pca()` to perform a principal components analysis,\n",
    "- `pyemma.coordinates.tica()` to perform a time-lagged independent component analysis, and\n",
    "- `pyemma.coordinates.vamp()` to analyze the quality of some feature spaces, perform dimension reduction, and\n",
    "- `pyemma.coordinates.cluster_kmeans()` to perform a $k$-means clustering, and\n",
    "- `pyemma.coordinates.cluster_regspace()` to perform a regspace clustering.\n",
    "\n",
    "\n",
    "\n",
    "**Reading time**:\n",
    "~ 30 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter cheat sheet**:\n",
    "- to run the currently highlighted cell, hold <kbd>&#x21E7; Shift</kbd> and press <kbd>&#x23ce; Enter</kbd>;\n",
    "- to get help for a specific function, place the cursor within the function's brackets, hold <kbd>&#x21E7; Shift</kbd>, and press <kbd>&#x21E5; Tab</kbd>;\n",
    "- you can find the full documentation at [PyEMMA.org](http://www.pyemma.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Working with MD trajectories](#MD)    \n",
    "   1.1 [Loading trajectories](#load)   \n",
    "   1.2 [Selecting features](#feat)   \n",
    "   1.3 [Exercises](#exerc1)   \n",
    "2. [Dimensionality reduction and clustering](#dtraj)   \n",
    "   2.1 [Clustering](#clust)   \n",
    "   2.2 [Saving objects](#save)   \n",
    "   2.3 [Discrete trajectories](#disc)\n",
    "   2.4 [PCA, TICA, VAMP](#dim)   \n",
    "   2.5 [Exercises](#exerc2)   \n",
    "3. [Advanced exercises](#exerc3)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Working with MD trajectories\n",
    "<a id=\"MD\"></a>\n",
    "\n",
    "In this section you will learn how to load traejctories with pyemma and how to extract common features such as backbone dihedral angles from these trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's get all the necessary imports out of the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import mdshare\n",
    "import pyemma\n",
    "# for visualization of molecular structures:\n",
    "import nglview\n",
    "import mdtraj\n",
    "from threading import Timer\n",
    "from nglview.player import TrajectoryPlayer\n",
    "import seaborn as sbn\n",
    "sbn.set_context(\"paper\",font_scale=1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Loading a molecular trajectory in `*.xtc` format (alanine dipeptide)\n",
    "<a id=\"load\"></a>\n",
    "\n",
    "To load molecular dynamics data from one of the standard file formats e.g ( `*.xtc`),\n",
    "we need not only the actual simulation data, but a topology file, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb = mdshare.fetch('alanine-dipeptide-nowater.pdb', working_directory='data')\n",
    "files = mdshare.fetch('alanine-dipeptide-*-250ns-nowater.xtc', working_directory='data')\n",
    "print(pdb)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you just want to read `xyz` coordinates of your trajectories you can use the load function.\n",
    "\n",
    "⚠️The warning about **plain coordinates** is triggered,\n",
    "because these coordinates will include diffusion as a dynamical process,\n",
    "which might not be what one is interested in.\n",
    "If the molecule of interest has been aligned to a reference prior the analysis,\n",
    "it is fine to use these coordinates, but we will see that there are better choices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pyemma.coordinates.load(files, top=pdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise the structure using NGLview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget = nglview.show_mdtraj(mdtraj.load(pdb))\n",
    "p = TrajectoryPlayer(widget)\n",
    "widget.add_ball_and_stick()\n",
    "p.spin = True\n",
    "def stop_spin():\n",
    "    p.spin = False\n",
    "    widget.close()\n",
    "Timer(30, stop_spin).start()\n",
    "widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Selecting features\n",
    "<a id=\"feat\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyEMMA, the `featurizer` is a central object that incorporates the system's topology.\n",
    "We start by creating it using the topology file.\n",
    "Features are now easily computed by adding the target feature.\n",
    "If no feature is added, the featurizer will extract Cartesian coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pass the featurizer to the load function to extract the Cartesian coordinates from the trajectory files into memory.\n",
    "⚠️ For real world examples it is best to use the `source()` function,\n",
    "because not all your simulation data may fit into your workstations memory. \n",
    "\n",
    "⚠️The warning about **plain coordinates** is triggered,\n",
    "because these coordinates will include diffusion as a dynamical process,\n",
    "which might not be what one is interested in.\n",
    "If the molecule of interest has been aligned to a reference prior the analysis,\n",
    "it is fine to use these coordinates, but we will see that there are better choices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "print('type of data:', type(data))\n",
    "print('lengths: %d' %len(data))\n",
    "print('shape of elements: ', data[0].shape)\n",
    "print('n_atoms: %d' %feat.topology.n_atoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we start adding features which we want to extract from the simulation data.\n",
    "Here, we want to load the backbone torsions,\n",
    "because these angles are known to describe all flexibility in the system.\n",
    "Since this feature is two dimensional, it is also easier to visualize.\n",
    "Please note that, in complex systems, it is not trivial to visualize plain input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat.add_backbone_torsions(periodic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Please note that the trajectories have been aligned to a reference structure before.\n",
    "Since in this case we loose track of the periodic box,\n",
    "we have to switch off the `periodic` flag for the torsion angle computations.\n",
    "By default PyEMMA assumes your simulation uses periodic boundary conditions.\n",
    "\n",
    "We can always call the featurizer's `describe()` method to show which features are requested.\n",
    "You might have noticed that you can combine arbitrary features by having multiple calls to `add_` methods of the featurizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "\n",
    "print('type of data:', type(data))\n",
    "print('lengths:', len(data))\n",
    "print('shape of elements:', data[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have selected all desired features,\n",
    "we can call the `load()` function to load all features into memory or,\n",
    "alternatively, the `source()` function to create a streamed feature reader.\n",
    "For now, we will use `load()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feat.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualsing data\n",
    "Apparently, we have loaded a list of three two-dimensional `numpy.ndarray` objects from our three trajectory files.\n",
    "We can visualize these features using the aforementioned plotting functions,\n",
    "but to do so we have to concatenate the three individual trajectories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concatenated = np.concatenate(data)\n",
    "pyemma.plots.plot_feature_histograms(data_concatenated, feature_labels=feat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use PyEMMA's `plot_density()` and `plot_free_energy()` functions to create Ramachandran plots of our system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharex=True, sharey=True)\n",
    "# the * operator used in a function call is used to unpack\n",
    "# the iterable variable into its single elements. \n",
    "pyemma.plots.plot_density(*data_concatenated.T, ax=axes[0])\n",
    "pyemma.plots.plot_free_energy(*data_concatenated.T, ax=axes[1], legacy=True)\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel('$\\phi$')\n",
    "    ax.set_aspect('equal')\n",
    "axes[0].set_ylabel('$\\psi$')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Please note that these functions visualise the density and free energy of the sampled data, not the equilibrium distribution of the underlying system. To account for non-equiblibrium data, you can supply frame-wise weights using the weights parameter, which will be covered later. \n",
    "\n",
    "However, you can clearly see different basins which will be used for the MSM construction later. \n",
    "\n",
    "#### Heavy atoms feature\n",
    "Let us look at a different featurization example and load the positions of all heavy atoms instead.\n",
    "We create a new featurizer object and use its `add_selection()` method to request the positions of a given selection of atoms.\n",
    "For this selection, we can use the `select_Heavy()` method which returns the indices of all heavy atoms.\n",
    "\n",
    "Again, we load the data into memory and show what we loaded using the `describe()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat.add_selection(feat.select_Heavy())\n",
    "\n",
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "\n",
    "feat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Please note that PyEMMA has flattened the $x, y$ and $z$ coordinates into an array that will be used for further analysis.\n",
    "\n",
    "We visualize the distributions of all loaded features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "pyemma.plots.plot_feature_histograms(np.concatenate(data), feature_labels=feat, ax=ax)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `load()` versus `source()`\n",
    "\n",
    "Using `load()`, we put the full data into memory.\n",
    "This is possible for all examples in this tutorial.\n",
    "\n",
    "Many real world applications, though, require more memory than your workstation might provide.\n",
    "For these cases, you should use the `source()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pyemma.coordinates.source(files, features=feat)\n",
    "print(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates a reader, wich allows to stream the underlying data in chunks instead of the full set.\n",
    "Most of the functions in the `coordinates` sub-package accept data in memory as well as readers.\n",
    "However, some plotting functions require the data to be in memory.\n",
    "To load a (sub-sampled) subset into memory, we can use the `get_output()` method with a stride parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output = reader.get_output(stride=5)\n",
    "len(data_output)\n",
    "print('number of frames in first file: {}'.format(reader.trajectory_length(0)))\n",
    "print('number of frames after striding: {}'.format(len(data_output[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have loaded every fifth frame into memory.\n",
    "Again, we can visualize the (concatenated) features with a feature histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    np.concatenate(data_output), feature_labels=feat, ax=ax)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Exercises on loading data and extracting features\n",
    "<a id='exerc1'></a>\n",
    "\n",
    "The exercises are announced by the keyword **Exercise** and followed by an incomplete cell.\n",
    "Missing parts are indicated by\n",
    "```python\n",
    "#FIXME\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.3.1: Heavy atom distances\n",
    "\n",
    "Please fix the following code block such that the distances between all heavy atoms are loaded and visualized.\n",
    "\n",
    "**Hint**: try to use the auto-complete feature on the feat object to gain some insight.\n",
    "Also take a look at the previous demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "pairs = feat.pairs(# FIXME)\n",
    "feat. #FIXME\n",
    "\n",
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    np.concatenate(data), feature_labels=feat, ax=ax)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "pairs = feat.pairs(feat.select_Heavy())\n",
    "feat.add_distances(pairs)\n",
    "\n",
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    np.concatenate(data), feature_labels=feat, ax=ax)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.3.2: Write out heavy atom distances\n",
    "\n",
    "Please fix the following code to write out heavy atom distances to file and load them again\n",
    "\n",
    "**Hint**: try to use the auto-complete feature on the feat object to gain some insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat. #FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat.save('test.obj', overwrite=True)\n",
    "heavy_atoms = pyemma.load('test.obj')\n",
    "print(heavy_atoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.3.3: Torsion angles again...\n",
    "\n",
    "Please fix the following code to compute the `sin` and `cos` of the backbone torsional angles, as well as plot these features?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat. #FIXME\n",
    "\n",
    "print(feat.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pyemma.coordinates.#FIXME\n",
    "data_concatenated = #FIXME\n",
    "pyemma.plots.#FIXME\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat.add_backbone_torsions(cossin=True, periodic=False)\n",
    "\n",
    "print(feat.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we visualize the (concatenated) features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "data_concatenated = np.concatenate(data)\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "pyemma.plots.plot_feature_histograms(data_concatenated, feature_labels=feat, ax=ax)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.3.4\n",
    "\n",
    "Complete the following code block to load/visualize the position of all backbone atoms.\n",
    "\n",
    "**Hint**: You might find the `select_Backbone()` method of the featurizer object helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat. #FIXME\n",
    "\n",
    "# Concatanate the data\n",
    "#FIXME\n",
    "\n",
    "# Plot the data\n",
    "#FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat.add_selection(feat.select_Backbone())\n",
    "\n",
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "data_concatenated = np.concatenate(data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "pyemma.plots.plot_feature_histograms(data_concatenated, feature_labels=feat, ax=ax)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dimensionality Reduction and Clustering\n",
    "<a id=\"dtraj\"></a>\n",
    "\n",
    "In this section we will look at how we can obtain a discrete trajectory from the features of the molecular trajectory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Clustering\n",
    "<a id=\"clust\"></a>\n",
    "Let's go back to the nice backbone torsion view and use these to cluster data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat.add_backbone_torsions(periodic=False)\n",
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "data_concatenated = np.concatenate(data)\n",
    "print(feat.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be looking at two clsutering methods [kmeans](https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html) and 'regular spatial'.  \n",
    "\n",
    "With only 2 torsional angles, we can directly attempt to discretize or cluster the data,\n",
    "e.g., with $k$-means with $100$ centers and a stride of $10$ to reduce the computational effort.\n",
    "In real world examples we also might encounter low dimensional feature spaces\n",
    "which do not require further dimension reduction techniques to be clustered efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_kmeans = pyemma.coordinates.cluster_kmeans(data, k=100, max_iter=50, stride=10, n_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or with a regspace technique where all centers should have a minimal pairwise distance of $0.5$ units of length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regular spacial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_regspace = pyemma.coordinates.cluster_regspace(data, dmin=0.3,  n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharex=True, sharey=True)\n",
    "for ax, cls in zip(axes.flat, [cluster_kmeans, cluster_regspace]):\n",
    "    pyemma.plots.plot_density(*data_concatenated.T, ax=ax, cbar=False, alpha=0.1, logscale=True)\n",
    "    ax.scatter(*cls.clustercenters.T, s=15, c='C1')\n",
    "    ax.set_xlabel('$\\phi$')\n",
    "    ax.set_ylabel('$\\psi$')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you noticed how the $k$-means centers follow the density of the data points while the regspace centers are spread uniformly over the whole area? \n",
    "\n",
    "If your are only interested in well sampled states, you should use a density based method to discretize.\n",
    "If exploring new states is one of your objectives,\n",
    "it might be of advantage to place states also in rarely observed regions.\n",
    "The latter is especially useful in adaptive sampling approaches,\n",
    "because in the initial phase you want to explore the phase space as much as possible.\n",
    "The downside of placing states in areas of low density is that we will have poor statistics on these states. \n",
    "\n",
    "Another advantage of regular space clustering is that it is fast in comparison to $k$-means:\n",
    "regspace clustering runs in linear time while $k$-means is superpolynomial in time.\n",
    "\n",
    "⚠️ For large datasets we also offer a mini batch version of $k$-means which has the same semantics as the original method but trains the centers on subsets of your data.\n",
    "This tutorial does not cover this case, but you should keep in mind that $k$-means requires your low dimensional space to fit into your main memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Saving and restoring the clustering object\n",
    "<a id=\"save\"></a>\n",
    "\n",
    "You noticed how the clustering even with the relatively small dataset took a substantial amount of time it would be good to not having to rerun the clustering every time and be able to save this information. \n",
    "\n",
    "PyEMMA provides a convenience method for saving these objects. \n",
    "Just try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_kmeans.save('kmeans.pyemma', model_name='ala_kmeans_100', overwrite=True)\n",
    "cluster_regspace.save('regspatial.pyemma', model_name='ala_regspace', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have stored the current state of the clustering estimator to disk.\n",
    "A file can contain multiple models, this is why we have used the `model_name` argument to specify the name.\n",
    "If omitted, the estimator will be saved under the name `default_model`.\n",
    "\n",
    "Assume that we have restarted our Python session and do not want to re-compute everything.\n",
    "We can now restore the previously saved estimator via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_restored = pyemma.load('kmeans.pyemma', model_name='ala_kmeans_100')\n",
    "\n",
    "# check that nothing has changed\n",
    "np.testing.assert_allclose(cluster_restored.clustercenters, cluster_kmeans.clustercenters, atol=1e-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the contents of a file, you can utilize the list_models function of PyEMMA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemma.list_models('kmeans.pyemma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Discrete trajectory generation\n",
    "<a id=\"disc\"></a>\n",
    "The main result of a discretization for Markov modeling, however,\n",
    "is not the set of centers but the time series of discrete states.\n",
    "These are accessible via the `dtrajs` attribute of any clustering object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_kmeans.dtrajs)\n",
    "print(cluster_regspace.dtrajs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each trajectory passed to the clustering object, we get a corresponding discrete trajectory.\n",
    "\n",
    "Please note that as an alternative to clustering algorithms such as $k$-means and regspace,\n",
    "it is possible to manually assign the data to cluster centers using the `pyemma.coordinates.assign_to_centers()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. PCA, TICA, VAMP \n",
    "<a id=\"#dim\"></a>\n",
    "\n",
    "Instead of discretizing the full (two-dimensional) space, we can attempt to find a one-dimensional subspace which\n",
    "1. describes the slow dynamics of the data set equally well but\n",
    "2. is easier to discretize.\n",
    "\n",
    "One widespread method for dimension reduction is [principal component analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) which finds a subspace with maximized variance. In pyemma you can use it in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = pyemma.coordinates.pca(data, dim=1)\n",
    "pca_output = pca.get_output()\n",
    "print(pca_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another technique is the time-lagged independent component analysis (TICA) which finds a subspace with maximized autocorrelation <a id=\"ref-1\" href=\"#cite-tica2\">molgedey-94</a>, <a id=\"ref-2\" href=\"#cite-tica\">perez-hernandez-13</a>.\n",
    "To compute the autocorrelation, we need a time shifted version of the data.\n",
    "This time shift is specified by the `lag` argument.\n",
    "For the current example, we choose a lag time of $1$ step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tica = pyemma.coordinates.tica(data, dim=1, lag=1)\n",
    "tica_output = tica.get_output()\n",
    "print(tica_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of TICA, we can also employ the variational approach for Markov processes (VAMP) to obtain a coordinate transform <a id=\"ref-3\" href=\"#cite-vamp-preprint\">wu-17</a>.\n",
    "In contrast to TICA, VAMP can be applied to non-equilibrium / non-reversible data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vamp = pyemma.coordinates.vamp(data, dim=1, lag=1)\n",
    "vamp_output = vamp.get_output()\n",
    "print(vamp_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ While there are many cases where PCA can find a suitable subspace,\n",
    "there are also many cases where the PCA-based subspace neglects the slow dynamics.\n",
    "\n",
    "In our example, the slow process is the jump along the $\\phi$ coordinate. For all three methods, we show the distribution after projecting the full dynamics onto a one-dimensional subspace (left) and the direction of projection (right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_concatenated = pca_output[0]\n",
    "tica_concatenated = tica_output[0]\n",
    "vamp_concatenated = vamp_output[0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    np.concatenate([pca_concatenated, tica_concatenated, vamp_concatenated], axis=1),\n",
    "    feature_labels=['PCA', 'TICA', 'VAMP'],\n",
    "    ax=axes[0])\n",
    "pyemma.plots.plot_density(*data_concatenated.T,ax=axes[1], cbar=False, alpha=0.1, logscale=True)\n",
    "axes[1].plot(\n",
    "    [0, 3 * pca.eigenvectors[0, 0]],\n",
    "    [0, 3 * pca.eigenvectors[1, 0]],\n",
    "    linewidth=3,\n",
    "    label='PCA')\n",
    "axes[1].plot(\n",
    "    [0, 3 * tica.eigenvectors[0, 0]],\n",
    "    [0, 3 * tica.eigenvectors[1, 0]],\n",
    "    linewidth=3,\n",
    "    label='TICA')\n",
    "axes[1].plot(\n",
    "    [0, 3 * vamp.singular_vectors_right[0, 0]],\n",
    "    [0, 3 * vamp.singular_vectors_right[1, 0]],\n",
    "    linewidth=3,\n",
    "    label='VAMP')\n",
    "axes[1].set_xlabel('$\\phi$')\n",
    "axes[1].set_ylabel('$\\psi$')\n",
    "#axes[1].set_xlim(-4, 4)\n",
    "#axes[1].set_ylim(-4, 4)\n",
    "#axes[1].set_aspect('equal')\n",
    "axes[1].legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that TICA and VAMP project along the $\\phi$-axis and, thus, yield a subspace which clearly resolves both metastable states.\n",
    "PCA on the other hand projects closely along the $\\psi$-axis and resolves a metastable state between the $\\alpha$-helix and $\\beta$-sheet space in the Ramachandran plot, but not along to the L-$\\alpha$ minimum.\n",
    "This is a case in point where variance maximization does not find a subspace which resolves the slowest dynamics of the system.\n",
    "\n",
    "This effect can also be seen when we plot the subspace time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "ax.plot(pca_concatenated[:300], label='PCA')\n",
    "ax.plot(tica_concatenated[:300], label='TICA')\n",
    "# note that for better comparability, we enforce the same direction as TICA\n",
    "ax.plot(vamp_concatenated[:300] * -1, label='VAMP')\n",
    "ax.set_xlabel('time / steps')\n",
    "ax.set_ylabel('feature values')\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all TICA/VAMP and PCA, we observe two different sets of metastable states. PCA resolves metastability along $\\psi$ a and VAMP and TICA along $\\phi$. In the analysis later on it will become clear that this is in fact the coordinate for the slowest dynamics of the system. \n",
    "\n",
    "In many applications, however, we also need to understand what our coordinate transform means in physical terms.\n",
    "This, in general, might be less obvious.\n",
    "Hence, it might be instructive to inspect the correlations of features to the independent components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "i = ax.imshow(tica.feature_TIC_correlation, cmap='bwr', vmin=-1, vmax=1)\n",
    "\n",
    "ax.set_xticks([0])\n",
    "ax.set_xlabel('IC')\n",
    "\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_ylabel('input feature')\n",
    "\n",
    "fig.colorbar(i);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example, we clearly see a significant correlation between the $\\phi$ component of the input data and the first independent component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ In practice you almost never would like to use PCA as dimension reduction method in MSM building,\n",
    "as it does not preserve kinetic variance. We are showing it here in these exercises to make this point clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = pyemma.coordinates.cluster_kmeans(tica, k=10, stride=5) # use only 1/5 of the input data to find centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now just obtain the discrete trajectories by accessing the property on the cluster instance.\n",
    "This will get all the TICA projected trajectories and assign them to the centers computed on the reduced data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrajs = cluster.dtrajs\n",
    "print('Assignment:', dtrajs)\n",
    "dtrajs_len = [len(d) for d in dtrajs]\n",
    "for dtraj_len, input_len in zip(dtrajs_len, reader.trajectory_lengths()):\n",
    "    print('Input length:', input_len, '\\tdtraj length:', dtraj_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Exercises\n",
    "<a id='exerc2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.5.1: Data loading and using PCA on that dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the heavy atoms' positions into memory. Discretizing a $30$-dimensional feature space is impractical.\n",
    "Let's use PCA to find a low-dimensional projection and visualize the marginal distributions of all principal components (PCs) as well as the joint distributions for the first two PCs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat. #FIXME\n",
    "data = pyemma.coordinates.load(#FIXME)\n",
    "\n",
    "print('We have {} features.'.format(feat.dimension()))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "pyemma.plots.plot_feature_histograms(np.concatenate(data), feature_labels=feat, ax=ax)\n",
    "fig.tight_layout()\n",
    "\n",
    "# PCA dimensionality reduction\n",
    "pca = #FIXME\n",
    "pca_concatenated = np.concatenate(#FIXME)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3), sharex=True)\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    pca_concatenated, ['PC {}'.format(i + 1) for i in range(pca.dimension())], ax=axes[0])\n",
    "pyemma.plots.plot_density(*pca_concatenated[:, :2].T, ax=axes[1], cbar=False, logscale=True)\n",
    "pyemma.plots.plot_free_energy(*pca_concatenated[:, :2].T, ax=axes[2], legacy=False)\n",
    "for ax in axes.flat[1:]:\n",
    "    ax.set_xlabel('PC 1')\n",
    "    ax.set_ylabel('PC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat.add_selection(feat.select_Heavy())\n",
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "\n",
    "print('We have {} features.'.format(feat.dimension()))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "pyemma.plots.plot_feature_histograms(np.concatenate(data), feature_labels=feat, ax=ax)\n",
    "fig.tight_layout()\n",
    "\n",
    "# PCA dimensionality reduction\n",
    "pca = pyemma.coordinates.pca(data)\n",
    "pca_concatenated = np.concatenate(pca.get_output())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3), sharex=True)\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    pca_concatenated, ['PC {}'.format(i + 1) for i in range(pca.dimension())], ax=axes[0])\n",
    "pyemma.plots.plot_density(*pca_concatenated[:, :2].T, ax=axes[1], cbar=False, logscale=True)\n",
    "pyemma.plots.plot_free_energy(*pca_concatenated[:, :2].T, ax=axes[2], legacy=False)\n",
    "for ax in axes.flat[1:]:\n",
    "    ax.set_xlabel('PC 1')\n",
    "    ax.set_ylabel('PC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default parameters, PCA will return as many dimensions as necessary to explain $95\\%$ of the variance;\n",
    "in this case, we have found a five-dimensional subspace which does seem to resolve some metastability in the first three principal components.\n",
    "\n",
    "#### Exercise 2.5.2: TICA visualization\n",
    "\n",
    "Apply TICA and visualize the marginal distributions of all independent components (ICs) as well as the joint distributions of the first two ICs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "tica =  #FIXME\n",
    "tica_concatenated = np.concatenate(tica.get_output())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    tica_concatenated, ['IC {}'.format(i + 1) for i in range(tica.dimension())], ax=axes[0])\n",
    "pyemma.plots.plot_density(*tica_concatenated[:, :2].T, ax=axes[1], cbar=False, logscale=True)\n",
    "pyemma.plots.plot_free_energy(*tica_concatenated[:, :2].T, ax=axes[2], legacy=False)\n",
    "for ax in axes.flat[1:]:\n",
    "    ax.set_xlabel('IC 1')\n",
    "    ax.set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "tica = pyemma.coordinates.tica(data)\n",
    "tica_concatenated = np.concatenate(tica.get_output())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    tica_concatenated, ['IC {}'.format(i + 1) for i in range(tica.dimension())], ax=axes[0])\n",
    "pyemma.plots.plot_density(*tica_concatenated[:, :2].T, ax=axes[1], cbar=False, logscale=True)\n",
    "pyemma.plots.plot_free_energy(*tica_concatenated[:, :2].T, ax=axes[2], legacy=False)\n",
    "for ax in axes.flat[1:]:\n",
    "    ax.set_xlabel('IC 1')\n",
    "    ax.set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.3 Exercise: TICA correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TICA, by default, uses a lag time of $10$ steps, kinetic mapping and a kinetic variance cutoff of $95\\%$ to determine the number of ICs.\n",
    "We observe that this projection does resolve some metastability in both ICs.\n",
    "Whether these projections are suitable for building Markov state models, though, remains to be seen in later on.\n",
    "\n",
    "As we discussed in the first example, the physical meaning of the TICA projection is not directly clear.\n",
    "We can analyze the feature TIC correlation as we did above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3, 8))\n",
    "i = ax.imshow(#FIXME, cmap='bwr')\n",
    "\n",
    "ax.set_xticks(range(tica.dimension()))\n",
    "ax.set_xlabel('IC')\n",
    "\n",
    "ax.set_yticks(range(feat.dimension()))\n",
    "ax.set_yticklabels(feat.describe())\n",
    "ax.set_ylabel('input feature')\n",
    "\n",
    "fig.colorbar(i);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3, 8))\n",
    "i = ax.imshow(tica.feature_TIC_correlation, cmap='bwr')\n",
    "\n",
    "ax.set_xticks(range(tica.dimension()))\n",
    "ax.set_xlabel('IC')\n",
    "\n",
    "ax.set_yticks(range(feat.dimension()))\n",
    "ax.set_yticklabels(feat.describe())\n",
    "ax.set_ylabel('input feature')\n",
    "\n",
    "fig.colorbar(i);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not helpful as it only shows that some of our $x, y, z$-coordinates correlate with the TICA components.\n",
    "Since we rather expect the slow processes to happen in backbone torsion space, this comes to no surprise. \n",
    "\n",
    "To understand what the TICs really mean, let us do a more systematic approach and scan through some angular features.\n",
    "We add some randomly chosen angles between heavy atoms and the backbone angles that we already know to be a good feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_test = pyemma.coordinates.featurizer(pdb)\n",
    "feat_test.add_backbone_torsions(periodic=False)\n",
    "feat_test.add_angles(feat_test.select_Heavy()[:-1].reshape(3, 3), periodic=False)\n",
    "data_test = pyemma.coordinates.load(files, features=feat_test)\n",
    "data_test_concatenated = np.concatenate(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, we use scipy's implementation of Pearson's correlation coefficient which we compute between our test features and TICA projected $x, y, z$-coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "test_feature_TIC_correlation = np.zeros((feat_test.dimension(), tica.dimension()))\n",
    "\n",
    "for i in range(feat_test.dimension()):\n",
    "    for j in range(tica.dimension()):\n",
    "        test_feature_TIC_correlation[i, j] = pearsonr(\n",
    "            data_test_concatenated[:, i],\n",
    "            tica_concatenated[:, j])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm = abs(test_feature_TIC_correlation).max()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "i = ax.imshow(test_feature_TIC_correlation, vmin=-vm, vmax=vm, cmap='bwr')\n",
    "\n",
    "ax.set_xticks(range(tica.dimension()))\n",
    "ax.set_xlabel('IC')\n",
    "\n",
    "ax.set_yticks(range(feat_test.dimension()))\n",
    "ax.set_yticklabels(feat_test.describe())\n",
    "ax.set_ylabel('input feature')\n",
    "\n",
    "fig.colorbar(i);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this simple analysis, we find that features that correlated most with our TICA projection are indeed the backbone torsion angles used previously.\n",
    "We might thus expect the dynamics in TICA space to be similar to the one in backbone torsion space.\n",
    "\n",
    "⚠️ Please note that in general, we do not know which feature would be a good observable.\n",
    "Thus, a realistic scenario might require a much broader scan of a large set of different features.\n",
    "\n",
    "However, it should be mentioned that TICA projections do not necessarily have a simple physical interpretation.\n",
    "The above analysis might very well end with feature TIC correlations that show no significant contributor and rather hint towards a complicated linear combination of input features.\n",
    "\n",
    "\n",
    "#### Exercise 2.5.4: PCA parameters\n",
    "\n",
    "Perform PCA on the heavy atoms' positions data set with a target dimension of two;\n",
    "then discretize the two-dimensional subspace using $k$-means with $100$ centers and a stride of $15$ to reduce the computational effort.\n",
    "\n",
    "**Hint:** Look up the parameters of `pyemma.coordinates.pca()`, especially the `dim` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "pca =  # FIXME\n",
    "pca_concatenated =  # FIXME\n",
    "\n",
    "cluster = pyemma.coordinates.cluster_kmeans(pca, k=100, max_iter=50, stride=15, n_jobs=2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    pca_concatenated, ['PC {}'.format(i + 1) for i in range(pca.dimension())], ax=axes[0])\n",
    "pyemma.plots.plot_density(*pca_concatenated.T, ax=axes[1], cbar=False, alpha=0.1, logscale=True)\n",
    "axes[1].scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "axes[1].set_xlabel('PC 1')\n",
    "axes[1].set_ylabel('PC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "pca = pyemma.coordinates.pca(data, dim=2)\n",
    "pca_concatenated = np.concatenate(pca.get_output())\n",
    "\n",
    "cluster = pyemma.coordinates.cluster_kmeans(pca, k=100, max_iter=50, stride=15, n_jobs=2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    pca_concatenated, ['PC {}'.format(i + 1) for i in range(pca.dimension())], ax=axes[0])\n",
    "pyemma.plots.plot_density(*pca_concatenated.T, ax=axes[1], cbar=False, alpha=0.1, logscale=True)\n",
    "axes[1].scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "axes[1].set_xlabel('PC 1')\n",
    "axes[1].set_ylabel('PC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.5.5: TICA parameters\n",
    "\n",
    "Perform TICA at lag time $1$ step on the heavy atoms' positions data set with a target dimension of two;\n",
    "then discretize the two-dimensional subspace using $k$-means with $100$ centers and a stride of $5$ to reduce the computational effort.\n",
    "\n",
    "**Hint:** Look up the parameters of `pyemma.coordinates.tica()`, especially the `dim` and `lag` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "tica =  # FIXME\n",
    "tica_concatenated =  # FIXME\n",
    "\n",
    "cluster =  # FIXME\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    tica_concatenated, ['IC {}'.format(i + 1) for i in range(tica.dimension())], ax=axes[0])\n",
    "pyemma.plots.plot_density(*tica_concatenated.T, ax=axes[1], cbar=False, alpha=0.1, logscale=True)\n",
    "axes[1].scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "axes[1].set_xlabel('IC 1')\n",
    "axes[1].set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "tica = pyemma.coordinates.tica(data, lag=1, dim=2)\n",
    "tica_concatenated = np.concatenate(tica.get_output())\n",
    "\n",
    "cluster = pyemma.coordinates.cluster_kmeans(tica, k=100, max_iter=50, stride=1, n_jobs=2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    tica_concatenated, ['IC {}'.format(i + 1) for i in range(tica.dimension())], ax=axes[0])\n",
    "pyemma.plots.plot_density(*tica_concatenated.T, ax=axes[1], cbar=False, alpha=0.1, logscale=True)\n",
    "axes[1].scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "axes[1].set_xlabel('IC 1')\n",
    "axes[1].set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you noticed the difference in the first two ICs for lag times $10$ steps vs. $1$ step (e.g., result of exercises `2.5.2` and `2.5.3`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. More Exercises\n",
    "<a id=\"exerc3\"></a>\n",
    "Only try this exercise, if you have run out of time. \n",
    "\n",
    "Can you run the same analysis as you have shown in exercise 2.3.4, but using VAMP instead? Plot the ICs with the input features and the density plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat.add_selection(feat.select_Heavy())\n",
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "data_concatenated = np.concatenate(data)\n",
    "vamp = #FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat.add_selection(feat.select_Heavy())\n",
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "data_concatenated = np.concatenate(data)\n",
    "vamp = pyemma.coordinates.vamp(data_concatenated, lag=20, dim=3)\n",
    "vamp_concatenated = np.concatenate(vamp.get_output(stride=5))\n",
    "\n",
    "cluster = pyemma.coordinates.cluster_kmeans(vamp, k=100, max_iter=50, stride=15,n_jobs=2)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    tica_concatenated, ['IC {}'.format(i + 1) for i in range(tica.dimension())], ax=axes[0, 0])\n",
    "for ax, (i, j) in zip(axes.flat[1:], [[0, 1], [1, 2], [0, 2]]):\n",
    "    pyemma.plots.plot_density(*vamp_concatenated[:, [i, j]].T, ax=ax, cbar=False, alpha=0.1)\n",
    "    ax.scatter(*cluster.clustercenters[:, [i, j]].T, s=15, c='C1')\n",
    "    ax.set_xlabel('IC {}'.format(i + 1))\n",
    "    ax.set_ylabel('IC {}'.format(j + 1))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\n",
    "<a id=\"cite-tica2\"/><sup><a href=#ref-1>[^]</a></sup>Molgedey, L. and Schuster, H. G.. 1994. _Separation of a mixture of independent signals using time delayed correlations_. [URL](http://dx.doi.org/10.1103/PhysRevLett.72.3634)\n",
    "\n",
    "<a id=\"cite-tica\"/><sup><a href=#ref-2>[^]</a></sup>Guillermo Pérez-Hernández and Fabian Paul and Toni Giorgino and Gianni De Fabritiis and Frank Noé. 2013. _Identification of slow molecular order parameters for Markov model construction_. [URL](https://doi.org/10.1063/1.4811489)\n",
    "\n",
    "<a id=\"cite-vamp-preprint\"/><sup><a href=#ref-3>[^]</a></sup>Wu, H. and Noé, F.. 2017. _Variational approach for learning Markov processes from time series data_. [URL](https://arxiv.org/pdf/1707.04659.pdf)\n",
    "\n",
    "<a id=\"cite-aggarwal_surprising_2001\"/><sup><a href=#ref-4>[^]</a></sup>Aggarwal, Charu C. and Hinneburg, Alexander and Keim, Daniel A.. 2001. _On the Surprising Behavior of Distance Metrics in High Dimensional Space_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Disclaimer: \n",
    "This tutorial has been adapted from pyemma tutorials 01 and 02 (https://github.com/markovmodel/pyemma_tutorials)\n",
    "\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" title='This work is licensed under a Creative Commons Attribution 4.0 International License.' align=\"right\"/></a>\n",
    "\n",
    "Maintainers of the original notebooks [@cwehmeyer](https://github.com/cwehmeyer), [@marscher](https://github.com/marscher), [@thempel](https://github.com/thempel), [@psolsson](https://github.com/psolsson)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
